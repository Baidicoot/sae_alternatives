{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_vis import parse_feature_data, SaeVisConfig, SaeVisLayoutConfig, Column, ActsHistogramConfig, LogitsTableConfig, LogitsHistogramConfig, SequencesConfig\n",
    "from datasets import load_dataset\n",
    "from modelling_sae import normalize_dict\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from modelling_sae import BasicSAE, RICA\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/tmp/ipykernel_898596/988457238.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(dataset[\"input_ids\"]).cuda()\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"Elriggs/openwebtext-100k\", split=\"train[-10000:]\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-410m-deduped\")\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "MAX_LEN = 64\n",
    "NUM_FEATS = 64\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda x: tokenizer(x[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN),\n",
    "    batched=True,\n",
    ")\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\"])\n",
    "\n",
    "data = torch.tensor(dataset[\"input_ids\"]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b5ffbadf6e4c43adb1e59adf801590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-410m\").cuda()\n",
    "\n",
    "sae = BasicSAE(1024, 8192, 0).cuda()\n",
    "sae_state_dict = torch.load(\"models/epoch_9/basic_sae_1.05e-04.pt\")\n",
    "sae.load_state_dict(sae_state_dict)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "saved_feat_acts = []\n",
    "saved_model_acts = []\n",
    "saved_final_hidden_states = []\n",
    "\n",
    "is_nonnegative = True\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm.tqdm(range(0, data.shape[0], 128)):\n",
    "        batch = data[i:i+128]\n",
    "\n",
    "        hidden_states = model(batch, output_hidden_states=True).hidden_states\n",
    "        model_acts = hidden_states[8]\n",
    "        final_hidden_states = hidden_states[-1]\n",
    "        all_feat_acts = sae(model_acts.reshape(-1, 1024))[2].reshape(-1, MAX_LEN, 8192)[:, :, :NUM_FEATS]\n",
    "        \n",
    "        if not is_nonnegative:\n",
    "            all_feat_acts = torch.cat([all_feat_acts, -all_feat_acts], dim=-1)\n",
    "            all_feat_acts = torch.clamp(all_feat_acts, min=0)\n",
    "        \n",
    "        saved_feat_acts.append(all_feat_acts)\n",
    "        saved_model_acts.append(model_acts)\n",
    "        saved_final_hidden_states.append(final_hidden_states)\n",
    "\n",
    "model_acts = torch.cat(saved_model_acts, dim=0)\n",
    "all_feat_acts = torch.cat(saved_feat_acts, dim=0)\n",
    "final_hidden_states = torch.cat(saved_final_hidden_states, dim=0)\n",
    "\n",
    "feature_idxs = list(range(NUM_FEATS))\n",
    "\n",
    "if not is_nonnegative:\n",
    "    feature_idxs = list(range(NUM_FEATS * 2))\n",
    "\n",
    "if is_nonnegative:\n",
    "    feature_resid_dir = normalize_dict(sae.unembed)[:NUM_FEATS]\n",
    "elif not is_nonnegative:\n",
    "    feature_resid_dir = normalize_dict(sae.embed)[:NUM_FEATS]\n",
    "    feature_resid_dir = torch.cat([feature_resid_dir, -feature_resid_dir], dim=0)\n",
    "\n",
    "output_embed = model.embed_out.weight.data.T\n",
    "\n",
    "feat_tables_cfg = SaeVisLayoutConfig(\n",
    "    columns = [\n",
    "        Column(ActsHistogramConfig(), SequencesConfig(stack_mode='stack-none')),\n",
    "    ],\n",
    "    height=750\n",
    ")\n",
    "cfg = SaeVisConfig(\n",
    "    feature_centric_layout=feat_tables_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_vis_data = parse_feature_data(\n",
    "    tokens=data,\n",
    "    feature_indices=feature_idxs,\n",
    "    all_feat_acts=all_feat_acts,\n",
    "    feature_resid_dir=feature_resid_dir,\n",
    "    # feature_out_dir=feature_resid_dir,\n",
    "    all_resid_post=final_hidden_states,\n",
    "    W_U=output_embed,\n",
    "    cfg=cfg,\n",
    ")[0]\n",
    "\n",
    "class PointlessStupidity:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "sae_vis_data.model = PointlessStupidity(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_vis_data.save_feature_centric_vis(\"sae_vis.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 64])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
